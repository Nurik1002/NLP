{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a6fb255-d2f2-42fd-b831-4ceec3252414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3de7bfe-eca9-4209-bf95-3eecbc5e6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0431f6b2-f05a-45fa-9b00-871c173ad558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"I am a student from the University of Alabama. \n",
    "I was born in Ontario, Canada and I am a huge fan of the United States. \n",
    "I am going to get a degree in Philosophy to improve my chances of becoming a Philosophy professor. \n",
    "I have been working towards this goal for 4 years. \n",
    "I am currently enrolled in a PhD program. \n",
    "It is very difficult, but I am confident that it will be a good decision\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb2658b-c978-4e23-8b3f-02781bee4a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'student',\n",
       " 'from',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Alabama',\n",
       " '.',\n",
       " 'I',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Ontario',\n",
       " ',',\n",
       " 'Canada',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'Philosophy',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'my',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'becoming',\n",
       " 'a',\n",
       " 'Philosophy',\n",
       " 'professor',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'been',\n",
       " 'working',\n",
       " 'towards',\n",
       " 'this',\n",
       " 'goal',\n",
       " 'for',\n",
       " '4',\n",
       " 'years',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'a',\n",
       " 'PhD',\n",
       " 'program',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'very',\n",
       " 'difficult',\n",
       " ',',\n",
       " 'but',\n",
       " 'I',\n",
       " 'am',\n",
       " 'confident',\n",
       " 'that',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'decision']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_word_tokens = word_tokenize(sample_text)\n",
    "sample_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc3e6feb-ff37-47ce-9863-43a6bc6b903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am a student from the University of Alabama.',\n",
       " 'I was born in Ontario, Canada and I am a huge fan of the United States.',\n",
       " 'I am going to get a degree in Philosophy to improve my chances of becoming a Philosophy professor.',\n",
       " 'I have been\\nworking towards this goal for 4 years.',\n",
       " 'I am currently enrolled in a PhD program.',\n",
       " 'It is very difficult, but I am confident that it will be a good decision']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sent_tokenize = sent_tokenize(sample_text)\n",
    "sample_sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6390c122-3f0a-4730-af41-a79973d3e1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'ME',\n",
       " 'MY',\n",
       " 'MYSELF',\n",
       " 'WE',\n",
       " 'OUR',\n",
       " 'OURS',\n",
       " 'OURSELVES',\n",
       " 'YOU',\n",
       " \"YOU'RE\",\n",
       " \"YOU'VE\",\n",
       " \"YOU'LL\",\n",
       " \"YOU'D\",\n",
       " 'YOUR',\n",
       " 'YOURS',\n",
       " 'YOURSELF',\n",
       " 'YOURSELVES',\n",
       " 'HE',\n",
       " 'HIM',\n",
       " 'HIS',\n",
       " 'HIMSELF',\n",
       " 'SHE',\n",
       " \"SHE'S\",\n",
       " 'HER',\n",
       " 'HERS',\n",
       " 'HERSELF',\n",
       " 'IT',\n",
       " \"IT'S\",\n",
       " 'ITS',\n",
       " 'ITSELF',\n",
       " 'THEY',\n",
       " 'THEM',\n",
       " 'THEIR',\n",
       " 'THEIRS',\n",
       " 'THEMSELVES',\n",
       " 'WHAT',\n",
       " 'WHICH',\n",
       " 'WHO',\n",
       " 'WHOM',\n",
       " 'THIS',\n",
       " 'THAT',\n",
       " \"THAT'LL\",\n",
       " 'THESE',\n",
       " 'THOSE',\n",
       " 'AM',\n",
       " 'IS',\n",
       " 'ARE',\n",
       " 'WAS',\n",
       " 'WERE',\n",
       " 'BE',\n",
       " 'BEEN',\n",
       " 'BEING',\n",
       " 'HAVE',\n",
       " 'HAS',\n",
       " 'HAD',\n",
       " 'HAVING',\n",
       " 'DO',\n",
       " 'DOES',\n",
       " 'DID',\n",
       " 'DOING',\n",
       " 'A',\n",
       " 'AN',\n",
       " 'THE',\n",
       " 'AND',\n",
       " 'BUT',\n",
       " 'IF',\n",
       " 'OR',\n",
       " 'BECAUSE',\n",
       " 'AS',\n",
       " 'UNTIL',\n",
       " 'WHILE',\n",
       " 'OF',\n",
       " 'AT',\n",
       " 'BY',\n",
       " 'FOR',\n",
       " 'WITH',\n",
       " 'ABOUT',\n",
       " 'AGAINST',\n",
       " 'BETWEEN',\n",
       " 'INTO',\n",
       " 'THROUGH',\n",
       " 'DURING',\n",
       " 'BEFORE',\n",
       " 'AFTER',\n",
       " 'ABOVE',\n",
       " 'BELOW',\n",
       " 'TO',\n",
       " 'FROM',\n",
       " 'UP',\n",
       " 'DOWN',\n",
       " 'IN',\n",
       " 'OUT',\n",
       " 'ON',\n",
       " 'OFF',\n",
       " 'OVER',\n",
       " 'UNDER',\n",
       " 'AGAIN',\n",
       " 'FURTHER',\n",
       " 'THEN',\n",
       " 'ONCE',\n",
       " 'HERE',\n",
       " 'THERE',\n",
       " 'WHEN',\n",
       " 'WHERE',\n",
       " 'WHY',\n",
       " 'HOW',\n",
       " 'ALL',\n",
       " 'ANY',\n",
       " 'BOTH',\n",
       " 'EACH',\n",
       " 'FEW',\n",
       " 'MORE',\n",
       " 'MOST',\n",
       " 'OTHER',\n",
       " 'SOME',\n",
       " 'SUCH',\n",
       " 'NO',\n",
       " 'NOR',\n",
       " 'NOT',\n",
       " 'ONLY',\n",
       " 'OWN',\n",
       " 'SAME',\n",
       " 'SO',\n",
       " 'THAN',\n",
       " 'TOO',\n",
       " 'VERY',\n",
       " 'S',\n",
       " 'T',\n",
       " 'CAN',\n",
       " 'WILL',\n",
       " 'JUST',\n",
       " 'DON',\n",
       " \"DON'T\",\n",
       " 'SHOULD',\n",
       " \"SHOULD'VE\",\n",
       " 'NOW',\n",
       " 'D',\n",
       " 'LL',\n",
       " 'M',\n",
       " 'O',\n",
       " 'RE',\n",
       " 'VE',\n",
       " 'Y',\n",
       " 'AIN',\n",
       " 'AREN',\n",
       " \"AREN'T\",\n",
       " 'COULDN',\n",
       " \"COULDN'T\",\n",
       " 'DIDN',\n",
       " \"DIDN'T\",\n",
       " 'DOESN',\n",
       " \"DOESN'T\",\n",
       " 'HADN',\n",
       " \"HADN'T\",\n",
       " 'HASN',\n",
       " \"HASN'T\",\n",
       " 'HAVEN',\n",
       " \"HAVEN'T\",\n",
       " 'ISN',\n",
       " \"ISN'T\",\n",
       " 'MA',\n",
       " 'MIGHTN',\n",
       " \"MIGHTN'T\",\n",
       " 'MUSTN',\n",
       " \"MUSTN'T\",\n",
       " 'NEEDN',\n",
       " \"NEEDN'T\",\n",
       " 'SHAN',\n",
       " \"SHAN'T\",\n",
       " 'SHOULDN',\n",
       " \"SHOULDN'T\",\n",
       " 'WASN',\n",
       " \"WASN'T\",\n",
       " 'WEREN',\n",
       " \"WEREN'T\",\n",
       " 'WON',\n",
       " \"WON'T\",\n",
       " 'WOULDN',\n",
       " \"WOULDN'T\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [ word.upper() for word in stopwords.words('english')]\n",
    "stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ffdaec5-d7aa-4635-8656-2f91625f26a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student',\n",
       " 'University',\n",
       " 'Alabama',\n",
       " '.',\n",
       " 'born',\n",
       " 'Ontario',\n",
       " ',',\n",
       " 'Canada',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'United',\n",
       " 'States',\n",
       " '.',\n",
       " 'going',\n",
       " 'get',\n",
       " 'degree',\n",
       " 'Philosophy',\n",
       " 'improve',\n",
       " 'chances',\n",
       " 'becoming',\n",
       " 'Philosophy',\n",
       " 'professor',\n",
       " '.',\n",
       " 'working',\n",
       " 'towards',\n",
       " 'goal',\n",
       " '4',\n",
       " 'years',\n",
       " '.',\n",
       " 'currently',\n",
       " 'enrolled',\n",
       " 'PhD',\n",
       " 'program',\n",
       " '.',\n",
       " 'difficult',\n",
       " ',',\n",
       " 'confident',\n",
       " 'good',\n",
       " 'decision']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = [word for word in sample_word_tokens if word.upper() not in stop_words]\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fba2460b-4765-4d83-9e23-1ece3a2be80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08112cbc-7cb7-4960-8fbd-5c0f1195113a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'student',\n",
       " 'from',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Alabama',\n",
       " 'I',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Ontario',\n",
       " 'Canada',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'Philosophy',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'my',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'becoming',\n",
       " 'a',\n",
       " 'Philosophy',\n",
       " 'professor',\n",
       " 'I',\n",
       " 'have',\n",
       " 'been',\n",
       " 'working',\n",
       " 'towards',\n",
       " 'this',\n",
       " 'goal',\n",
       " 'for',\n",
       " '4',\n",
       " 'years',\n",
       " 'I',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'a',\n",
       " 'PhD',\n",
       " 'program',\n",
       " 'It',\n",
       " 'is',\n",
       " 'very',\n",
       " 'difficult',\n",
       " 'but',\n",
       " 'I',\n",
       " 'am',\n",
       " 'confident',\n",
       " 'that',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'decision']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_word_tokens =  tokenizer.tokenize(str(sample_word_tokens))\n",
    "sample_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8bc0623-b140-4d49-bc80-e03d73f51520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'student',\n",
       " 'from',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'alabama',\n",
       " 'i',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'ontario',\n",
       " 'canada',\n",
       " 'and',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'i',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'philosophy',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'my',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'becoming',\n",
       " 'a',\n",
       " 'philosophy',\n",
       " 'professor',\n",
       " 'i',\n",
       " 'have',\n",
       " 'been',\n",
       " 'working',\n",
       " 'towards',\n",
       " 'this',\n",
       " 'goal',\n",
       " 'for',\n",
       " '4',\n",
       " 'years',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'a',\n",
       " 'phd',\n",
       " 'program',\n",
       " 'it',\n",
       " 'is',\n",
       " 'very',\n",
       " 'difficult',\n",
       " 'but',\n",
       " 'i',\n",
       " 'am',\n",
       " 'confident',\n",
       " 'that',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'decision']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_word_tokens = [word.lower() for word in sample_word_tokens]\n",
    "sample_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab6b38-727f-468d-a745-66028aa01b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
